{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576065ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import cv2\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numba\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electronic-shoulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "TestSet1_folder = 'data/TestSet1'\n",
    "TestSet2_folder = 'data/TestSet2'\n",
    "TestSet3_folder = 'data/TestSet3'\n",
    "\n",
    "TestSet1_result_folder = 'result/TestSet1'\n",
    "TestSet2_result_folder = 'result/TestSet2'\n",
    "TestSet3_result_folder = 'result/TestSet3'\n",
    "\n",
    "os.makedirs(TestSet1_result_folder, exist_ok=True)\n",
    "os.makedirs(TestSet2_result_folder, exist_ok=True)\n",
    "os.makedirs(TestSet3_result_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7e98b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TestSet1_imgs = []\n",
    "for file in os.listdir(TestSet1_folder): \n",
    "    TestSet1_imgs.append(\n",
    "        cv2.cvtColor(np.asarray(Image.open(os.path.join(TestSet1_folder, file))),\n",
    "                     cv2.COLOR_BGR2GRAY)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdc1afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "TestSet2_imgs = []\n",
    "for file in os.listdir(TestSet2_folder): \n",
    "    TestSet2_imgs.append(\n",
    "        cv2.cvtColor(np.asarray(Image.open(os.path.join(TestSet2_folder, file))),\n",
    "                     cv2.COLOR_BGR2GRAY)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portable-speaker",
   "metadata": {},
   "outputs": [],
   "source": [
    "TestSet3_imgs = []\n",
    "for file in os.listdir(TestSet3_folder): \n",
    "    TestSet3_imgs.append(\n",
    "        cv2.cvtColor(np.asarray(Image.open(os.path.join(TestSet3_folder, file))),\n",
    "                     cv2.COLOR_BGR2GRAY)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-newman",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adaptive_thresholding:\n",
    "blockSize = 39\n",
    "C = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fc1dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_square(anchor):\n",
    "    x, y, w, h = cv2.boundingRect(anchor)\n",
    "    ratio = float(w)/h\n",
    "    return ratio >= 0.9 and ratio <= 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-simple",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_qr_codes_anchors(img):\n",
    "    # бинаризируем изображение\n",
    "    thresh_img = cv2.adaptiveThreshold(img, 255, \n",
    "            cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, blockSize=blockSize, C=C)\n",
    "    # ищем контуры\n",
    "    cnts, hierarchy = cv2.findContours(thresh_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    anchors = []\n",
    "    for i, cnt in enumerate(cnts):\n",
    "        # аппроксимирем многоугольником, ищем квадоты\n",
    "        cnt = cv2.approxPolyDP(cnt, 0.01*cv2.arcLength(cnt, True), closed=True)\n",
    "        if hierarchy[0][i][2] > 0 and hierarchy[0][i][3] > 0 and hierarchy[0][hierarchy[0][i][2]][2] > 0:\n",
    "            cnt = cv2.approxPolyDP(cnt, 10, closed=True)\n",
    "            if cnt.shape[0] == 4 and is_square(cnt):\n",
    "                anchors.append(cnt)\n",
    "    return (img, anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4776c7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, image in tqdm(list(enumerate(TestSet1_imgs))):\n",
    "    img, anchors = find_qr_codes_anchors(image)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    for anchor in anchors:\n",
    "        plt.plot(list(anchor[:, :, 0].flatten()) + list(anchor[:, :, 0][0]), \n",
    "                 list(anchor[:, :, 1].flatten()) + list(anchor[:, :, 1][0]))\n",
    "    plt.savefig(os.path.join(TestSet1_result_folder, f'img_{i}.png'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748635ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, image in tqdm(list(enumerate(TestSet2_imgs))):\n",
    "    img, anchors = find_qr_codes_anchors(image)    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    for anchor in anchors:\n",
    "        plt.plot(list(anchor[:, :, 0].flatten()) + list(anchor[:, :, 0][0]), \n",
    "                 list(anchor[:, :, 1].flatten()) + list(anchor[:, :, 1][0]))\n",
    "    plt.savefig(os.path.join(TestSet2_result_folder, f'img_{i}.png'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0644ded",
   "metadata": {},
   "source": [
    "Описание алгоритма: <br>\n",
    "    Адаптивно локально бинаризируем изображение\n",
    "    С помощью opencv находим контуры фигур и иерархию контуров <br>\n",
    "    Апроксимируем найденные контуры более простыми кривыми и ищем кривые приближенно похожие на квадраты <br>\n",
    "    Ищем с помощью найденных контуров и иерархии \"опорные\" точки qr-кодов\n",
    "    \n",
    "\n",
    "На один прогон изображений из двух TestSet'ов размером 116 картинок тратится ~ 1 минута 56 секунд. Итого время работы алгоритма ~1.22 секунды на изображение.\n",
    "\n",
    "\n",
    "Для TestSet1 имеем 63 правильных срабатываний и 3 неправильных, всего опорных точек на изображениях 144, т.е. **precision** ~95.5% и **recall** ~43.8% <br>\n",
    "Для TestSet2 множества имеем 106 правильных срабатываний и 6 неправильное, всего опорных точек на изображениях 147, т.е. **precision** ~94.6% и **recall** ~72.2% <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tight-springer",
   "metadata": {},
   "source": [
    "В целом можно воспользоватся функцией cv::QRCodeDetector::detect, чтобы найти сам QR-код, и уже внутри него искать паттерны. Но это, кажется, немного нечестным..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limiting-palmer",
   "metadata": {},
   "source": [
    "### TestSet3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secure-porter",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, image in tqdm(list(enumerate(TestSet3_imgs))):\n",
    "    img, anchors = find_qr_codes_anchors(image)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    for anchor in anchors:\n",
    "        plt.plot(list(anchor[:, :, 0].flatten()) + list(anchor[:, :, 0][0]), \n",
    "                 list(anchor[:, :, 1].flatten()) + list(anchor[:, :, 1][0]))\n",
    "    plt.savefig(os.path.join(TestSet3_result_folder, f'img_{i}.png'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dried-queens",
   "metadata": {},
   "source": [
    "Для TestSet3 множества имеем 356 правильных срабатываний и 70 неправильное, всего опорных точек на изображениях 483, т.е. precision ~83.6% и recall ~73.7%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
